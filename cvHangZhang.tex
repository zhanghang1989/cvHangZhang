%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Professional CV
% LaTeX Template

\documentclass{resume} % Use the custom resume.cls style
%\usepackage{hyperref}
%\usepackage{geometry}
\usepackage{graphicx}
\usepackage{listliketab}
\usepackage{array}
\usepackage{longtable}
\usepackage{comment}
\usepackage{natbib}
\usepackage{bibentry}
\usepackage[table]{xcolor}
\usepackage{xcolor,colortbl}

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry} % Document margins
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}

\definecolor{TableRed}{HTML}{800000}
\newcommand{\TextRed}[1]{\textcolor{TableRed}{#1}}

\name{Hang Zhang} % Your name

\address{\includegraphics[scale=0.3]{phone_number.png}}
\address{ zhanghang0704@gmail.com }

% \address{ zhang.hang@rutgers.edu \\ \url{http://hangzh.com}} % Your phone number and email

\begin{document}

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------
\begin{rSection}{About Me}
I am Hang Zhang, a Senior Staff Applied Research Scientist at Cruise, leading the efforts in Detection, Segmentation and Perception model consolidation. 
Before joining Cruise, I was a Research Scientist at Meta, and lead the effort in building a generic and scalable architecture optimization platform for AI products, serving various production models for IG, Portal and VR headsets on person understanding, AR/VR rendering and Ads ranking.
Before joining Meta, I was a Senior Applied Scientist in Amazon AI, where I worked on computer vision, deep learning and MXNet framework. We built ResNeSt model which achieved state-of-the-arts results on several major computer vision tasks.

% My research interests include neural architecture search, large scale image classification and segmentation. 

Beyond my work, I am also enthusiastic in contributing to open source projects, including \href{https://github.com/facebookresearch/d2go}{D2Go}, \href{https://github.com/facebookresearch/detectron2}{Detectron2}, \href{https://github.com/awslabs/autogluon/}{AutoGluon}, \href{https://github.com/zhanghang1989/PyTorch-Encoding}{PyTorch Encoding} and \href{https://github.com/dmlc/gluon-cv}{GluonCV}. More about me:
%I have organized {\it ``Everything you need to know to reproduce SoTA deep learning models''} in ICCV 2019.
%I have organized a tutorial series on {\it``From HPO to NAS: Automated Deep Learning''} on CVPR20 and ECCV20. 


[\href{https://hangzhang.org/}{Homepage}] [\href{https://github.com/zhanghang1989}{GitHub}] 
[\href{https://www.linkedin.com/in/zhanghang0704}{LinkedIn}] 
[\href{https://scholar.google.com/citations?user=gCoWdkUAAAAJ}{Google Scholar}]
\end{rSection}


%----------------------------------------------------------------------------------------
%	WORK EXPERIENCE SECTION
%----------------------------------------------------------------------------------------
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\begin{rSection}{Experience}

\begin{rSubsection}{Cruise AI}{\em Sep 2022 - Now}{Senior Staff Applied Research Scientist}{San Francisco, CA}
\item Lead the efforts in camera major model consolidation on object detection and segmentation in 2023. Leading the efforts in building a multi-task, multi-view, multi-modality, multi-frame and multi-platform model at Perception.
\item Lead the development of the Perception model training pipeline, which supports various projects on detection \& segmentation, longtailed understanding, lane detection, offboard foundation model, and online distillation.
\end{rSubsection}

\begin{rSubsection}{Meta Reality Lab (Facebook)}{\em Oct 2020 - Aug 2022}{Research Scientist}{Menlo Park, CA} %\RNum{2} 
\item Lead the development of FBNAS project, a unified pipeline for cross-platform hardware-aware model optimization. FBNAS has been applied to several production models in person understanding on IG, AR/VR applications and Ads models.
\item Developed and open sourced D2Go toolkit, bringing Detectron2 to mobile [\href{https://ai.facebook.com/blog/d2go-brings-detectron2-to-mobile/}{post}]
\item Research on efficient architectures, e.g. \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&sortby=pubdate&citation_for_view=gCoWdkUAAAAJ:ML0RJ9NH7IQC}{FBNetV5}, \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&sortby=pubdate&citation_for_view=gCoWdkUAAAAJ:p__nRnzSRKYC}{ScaleViT}. Co-organized workshop on ``Computer Vision for MetaVerse" in ECCV2022.
\end{rSubsection}

\begin{rSubsection}{Amazon AWS AI}{\em Jan 2018 - Oct 2020}{Senior Applied Scientist}{East Palo Alto, CA} %\RNum{2} 
\item Lead the development of GluonCV toolkit [\href{https://cv.gluon.ai/contents.html}{link}] and AutoGluon toolkit (for AutoML) [\href{https://auto.gluon.ai/stable/index.html}{link}]. 
\item Lead research on large scale vision solution, e.g. \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&citation_for_view=gCoWdkUAAAAJ:0KyAp5RtaNEC}{ResNeSt}, \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&citation_for_view=gCoWdkUAAAAJ:fEOibwPWpKIC}{Bag-of-tricks}, \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&citation_for_view=gCoWdkUAAAAJ:-_dYPAW6P2MC}{CFNet}, \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&sortby=pubdate&citation_for_view=gCoWdkUAAAAJ:35r97b3x0nAC}{dynamic SGD}. 
\item Organized 3 tutorials on \href{https://iccv2019.thecvf.com/program/tutorials}{ICCV19}, \href{http://hangzhang.org/CVPR2020/}{CVPR20} and \href{https://hangzhang.org/ECCV2020/}{ECCV20}. 
\end{rSubsection}

% \begin{rSubsection}{Rutgers University}{\em Jan 2014 - Oct 2017}{Research and Teaching Assistant}{New Brunswick, NJ}
% \item Material and texture modeling using deep learning algorithms. PhD Advisor: Prof. Kristin Dana
% \end{rSubsection}

\begin{rSubsection}{Amazon Lab 126 (Internship)}{\em May 2017 - Aug 2017}{Applied Scientist Intern}{Cupertino, CA}
\item Developed SoTA semantic segmentation algorithm of \href{https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gCoWdkUAAAAJ&sortby=pubdate&citation_for_view=gCoWdkUAAAAJ:9Nmd_mFXekcC}{EncNet} (Oral paper ($\sim$2.1\%) in CVPR 2018) [\href{https://www.youtube.com/watch?v=vAhzirU4WqA}{Talk link on YouTube}]
\end{rSubsection}

\begin{rSubsection}{NVIDIA (Internship)}{\em May 2016 - Aug 2016}{Deep learning Research Intern}{Holmdel, NJ}
\item Developed an end-to-end deep learning solution for autonomous driving. 
\item Implemented Torch to Caffe model converter [\href{https://github.com/zhanghang1989/fb-caffe-exts}{GitHub}].
\end{rSubsection}

\end{rSection}

\begin{rSection}{Education}

{\bf Rutgers University} \hfill {\em 2013 - 2017} \\
Ph.D. in Electrical and Computer Engineering \\
%Minor in Linguistics
%\smallskip
Thesis Advisor: Prof. Kristin Dana \\
Research Interest: Computer Vision\\
Current GPA: 3.9/4.0
%\smallskip

{\bf Southeast University (Nanjing, China)} \hfill {\em 2009 - 2013} \\
B.S. in School of Automation \\
Advisor: Prof. Junyang Li \\
 {\it Outstanding Undergraduate Thesis 2013} - School of Automation, Southeast University% award for best thesis in the department.
\end{rSection}


% \begin{rSection}{Technical Strengths}
% \begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
% Interested Area &  Deep Learning, Computer Vision. \\
% Programming Languages & C++, CUDA, Python, Lua, Matlab \\
% Deep Learning Toolbox & PyTorch, MXNet,  Torch\\ 

% \end{tabular}

% \end{rSection}


%\clearpage

\nobibliography{my}
\bibliographystyle{plain}
%\bibliographystyle{ieeetr}
\begin{rSection}{Publications}
\begin{enumerate}

\item \bibentry{chen2024CLAP}

\item \bibentry{liang2023open}

\item \bibentry{wu2021fbnetv5}

\item \bibentry{li2021investigation}

\item \bibentry{zhang2020resnest}

\item \bibentry{zhu2020improving}

\item \bibentry{Zhang_2019_CVPR}

\item \bibentry{Xie2018bags}

\item \bibentry{Lin2019elastic}

\item \bibentry{guo2019gluoncv}

\item\bibentry{kaur2017Photo}

\item \bibentry{Zhang_2018_CVPR}

\item \bibentry{xue18CVPR}

\item\bibentry{zhang17ICCV}

\item \bibentry{zhang2017thesis}

\item \bibentry{zhang17CVPR}

\item \bibentry{xue17CVPR}


\item \bibentry{zhang16CVPR}

\item \bibentry{zhang2015reflectance}

\end{enumerate}
\end{rSection}



% \begin{rSection}{Technical Awards}
% {\bf Amazon Off-cycle Research Grant} \hfill {2019} \\
% {\bf Doctoral Consortium Award} (CVPR 2017) \hfill {2017} \\
% {\bf NVIDIA Hardware Grant} \hfill{2016} \\
% {\bf TA/GA Professional Development Fund Award} (Rutgers) \hfill {2016}\\ 
% {\bf Outstanding Undergraduate Thesis Award} (SEU, China) \hfill {2013}\\
% {\bf Phoenix Contact Fellowship} (SEU, China) \hfill {2012} \\
% {\bf RoboCup: Robotics Navigation Competition 2nd Place Award} (SEU, China) \hfill {2012}

% \end{rSection}



\begin{rSection}{Academia Services}

{\bf Workshop and Tutorial Organizer} \\
{\it European Conference on Computer Vision (ECCV)} \hfill{Tel Aviv, 2022} \\ Computer Vision for MetaVerse \\

{\it European Conference on Computer Vision} (ECCV) \hfill{Glasgow, 2020}\\
From HPO to NAS: Automatic Deep Learning. \\

{\it IEEE Conference on Computer Vision and Pattern Recognition} (CVPR) \hfill{Seattle, 2020}\\
From HPO to NAS: Hands-on Tutorial on Automatic Deep Learning. \\

{\it IEEE International Conference on Computer Vision} (ICCV) \hfill{Seoul, 2019}\\
Everything You Need to Know to Reproduce SOTA Deep Learning Models: \\
Hands-on Tutorial for Training SOTA Computer Vision Models. \\

{\it Amazon Machine Learning Conference} (AMLC) \hfill{Seattle, 2018}\\
CNNs for Semantic Segmentation. 

{\bf Reviewer for Journals:} \\
{\it IEEE Transactions on Pattern Analysis and Machine Intelligence} (TPAMI) \\
{\it IEEE Transactions on Biomedical Circuits and Systems} (TbioCAS) \\
{\it Computer Vision and Image Understanding} (CVIU)

{\bf Program Committee and Reviewer for Conferences:} \\
{\it IEEE Conference on Computer Vision and Pattern Recognition} (CVPR) \hfill{2018 - 2021}\\
{\it IEEE International Conference on Computer Vision} (ICCV)  \hfill{2019 - 2021}\\
{\it European Conference on Computer Vision} (ECCV) \hfill{2018 - 2020}\\
{\it Conference on Neural Information Processing Systems} (NeurIPS) \hfill{2020 - 2021}\\
{\it IEEE Winter Conference on Applications of Computer Vision} (WACV)  \hfill{2018 - 2019}\\
SIGGRAPH  \hfill{2018}


\end{rSection}



\begin{comment}
\begin{rSection}{Relevant Course Work}
\begin{longtable}{p{0.8 in}|p{4.5in}p{1 in}}
	Fall 2015 & COMPUTER ARCHITECTURE &(16:332:563)\\
  	   & LINEAR ALGEBRA \& APPLICATIONS &(16:642:550)\\
    Spring 2015 & CONVEX OPTIMIZATION &(16:332:509)\\
    Fall 2014 & PATTERN RECOGNITION &(16:198:535)\\
  	   & PARALLEL \& DISTRIBUTED COMPUTING &(16:332:566)\\
	Spring 2014 & ROBUST COMPUTER VISION &(16:332:570)\\
  	   & SOFTWARE ENGINEERING II &(16:332:568)\\
  	   & DATA STRUCTURE \& ALGORITHMS &(16:332:573)\\ 	  Fall 2013  & MACHINE VISION &(16:332:561)\\
  	   & PROGRAMMING FINANCE &(16:332:503)\\
       & SYSTEM ANALYSIS &(16:332:501)\\
  
\end{longtable}
\end{rSection}

%----------------------
\begin{rSection}{Teaching Experience}
\begin{rSubsection}{Computer Architecture \& Assembly Language Lab}{Spring 2016\&17}{Teaching Assistant}{}
\item
Assisted in teaching Computer Architecture and Assembly Language Lab, including revising lab tutorials, managing course website, supervising the experiments and grading the lab reports. 
\end{rSubsection}
\begin{rSubsection}{Robotics \& Computer Vision}{Fall 2014}{Teaching Assistant}{}
\item
Assisted in teaching the Robotics and Computer Vision class under the supervision of Prof. Kristin Dana. This course includes common computer vision techniques such as image transformations, RANSAC, camera calibration, motion detection, and face recognition.
\end{rSubsection}

\end{rSection}

\end{comment}

\end{document}
